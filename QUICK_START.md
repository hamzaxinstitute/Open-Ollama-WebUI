# âš¡ Quick Start - One Command

## ğŸš€ Run Open Ollama WebUI in 30 seconds!

### Copy & Paste This Command:

```bash
curl -fsSL https://raw.githubusercontent.com/hamzaxinstitute/Open-Ollama-WebUI/main/setup.sh | bash
```

**That's it!** ğŸ‰

---

## What This Command Does:

1. âœ… **Checks Prerequisites** - Node.js, npm, Ollama
2. ğŸ“¦ **Downloads & Installs** - All dependencies automatically
3. ğŸŒ **Starts Server** - Opens at `http://localhost:5173`
4. ğŸ“– **Shows Instructions** - Helpful tips and next steps

---

## Alternative Methods:

### Method 1: Clone & Run
```bash
git clone https://github.com/hamzaxinstitute/Open-Ollama-WebUI.git
cd Open-Ollama-WebUI
./setup.sh
```

### Method 2: Windows Users
```cmd
git clone https://github.com/hamzaxinstitute/Open-Ollama-WebUI.git
cd Open-Ollama-WebUI
setup.bat
```

### Method 3: Manual Setup
```bash
git clone https://github.com/hamzaxinstitute/Open-Ollama-WebUI.git
cd Open-Ollama-WebUI
npm install && npm run dev
```

---

## Prerequisites:

- **Node.js 18+** - [Download](https://nodejs.org/)
- **Ollama** - [Download](https://ollama.ai/download)

---

## First Time Setup:

1. **Start Ollama**:
   ```bash
   ollama serve
   ```

2. **Download a Model**:
   ```bash
   ollama pull llama3.2
   ```

3. **Open WebUI**: Go to `http://localhost:5173`

---

## Need Help?

- ğŸ“– **Full Documentation**: See [README.md](README.md)
- ğŸ› **Report Issues**: [GitHub Issues](https://github.com/hamzaxinstitute/Open-Ollama-WebUI/issues)
- â­ **Star Repository**: Show your support!

---

**Ready to chat with AI? Run the command above! ğŸ¤–ğŸ’¬**
